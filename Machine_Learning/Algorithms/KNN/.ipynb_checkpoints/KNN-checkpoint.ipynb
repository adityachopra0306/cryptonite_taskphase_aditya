{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c843931-86d8-40ca-bf23-e6272c1d3377",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da50c68-6db9-4dd7-b489-1f0607306d94",
   "metadata": {},
   "source": [
    "# K Nearest Neighbour Classification Algorithm\n",
    "\n",
    "The K Nearest Neighbour (KNN) algorithm is a simple method for both classification and regression. With regards to classification, the algorithm assigns the class label to a sample based on the majority class of its nearest neighbors in the feature space.\n",
    "\n",
    "### Euclidean Distance\n",
    "\n",
    "In KNN, classification is done on the basis of nearest **Euclidean distance**. For two points $\\mathbf{x} = (x_1, x_2, ..., x_n) $ and $ \\mathbf{y} = (y_1, y_2, ..., y_n) $, the Euclidean distance is computed as:\n",
    "\n",
    "$$\n",
    "d(x, y) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}\n",
    "$$\n",
    "\n",
    "This formula calculates the straight-line distance between the points in $ n $-dimensional space.\n",
    "\n",
    "### KNN Classification Algorithm\n",
    "\n",
    "Given a training dataset, the KNN algorithm classifies a test datapoint based on the following steps:\n",
    "\n",
    "1. For each test sample, calculate the Euclidean distance from the test datapoint to all training examples.\n",
    "   \n",
    "2. From these distances, choose $k$ training exmaples with minimum distances to new datapoint.\n",
    "\n",
    "3. Classify the new point on the basis of the mode of the class labels of the $k$ training examples with min distance.\n",
    "\n",
    "The classification rule for KNN can be written as:\n",
    "\n",
    "$$\n",
    "\\hat{y}(\\mathbf{x_i}) = \\text{mode}_{1 \\leq j \\leq k} \\left( \\mathbf{y^j} \\right)\n",
    "$$\n",
    "\n",
    "Where $y^j$ is a label of the $k$ nearest neighbors, and $\\hat{y}(\\mathbf{x_i})$ is the most frequent label within these k samples.\n",
    "\n",
    "### Cross-Validation\n",
    "\n",
    "In KNN, the choice of $k$ affects the model's performance. To determine the optimal $k$, **cross-validation** is used.\n",
    "\n",
    "#### K-Fold Cross-Validation\n",
    "\n",
    "K-fold cross-validation is a technique where the dataset is divided into $k$ equal folds. The model is trained on $k-1$ folds and tested on the remaining fold. This process is repeated for each fold, and the average performance (such as accuracy) is calculated.\n",
    "\n",
    "The performance of the KNN classifier using cross-validation can be written as:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{1}{k} \\sum_{i=1}^{k} \\text{accuracy}(i)\n",
    "$$\n",
    "\n",
    "Where $\\text{accuracy}(i)$ is the accuracy on the $i$-th fold, and $k$ is the total number of folds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d4fdbd-d291-447e-b18c-b5059d3c0f3a",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dddd380-099d-4c02-9fea-5b58d16ba16f",
   "metadata": {},
   "source": [
    "### Importing Libraries and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76398122-3b25-4887-994b-c41db21f61db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "2    458\n",
       "4    241\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "df = pd.read_csv('dataset.csv').iloc[:,1:]\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4072b018-faf4-4bee-baaa-da58b6bbd1b9",
   "metadata": {},
   "source": [
    "### Z-Score Normalization and Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac630e4c-225b-419b-b7e2-6936d39f0a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bare_nuclei'] = pd.to_numeric(df['bare_nuclei'],errors=\"coerce\")\n",
    "df = df.dropna().astype('float64')\n",
    "\n",
    "features = df.drop(columns=['class'])\n",
    "features = (features-features.mean())/features.std()\n",
    "\n",
    "outliers = (abs(features)>3).any(axis=1)\n",
    "df = df[~outliers]\n",
    "features = features[~outliers]\n",
    "df.iloc[:,:-1] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17314316-b2c0-43b9-9523-3c9111f5508f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>unif_cell_size</th>\n",
       "      <th>unif_cell_shape</th>\n",
       "      <th>marg_adhesion</th>\n",
       "      <th>single_epith_cell</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chrom</th>\n",
       "      <th>norm_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.197760</td>\n",
       "      <td>-0.701698</td>\n",
       "      <td>-0.741230</td>\n",
       "      <td>-0.638897</td>\n",
       "      <td>-0.555202</td>\n",
       "      <td>-0.698341</td>\n",
       "      <td>-0.181694</td>\n",
       "      <td>-0.612478</td>\n",
       "      <td>-0.348145</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.197760</td>\n",
       "      <td>0.277049</td>\n",
       "      <td>0.262591</td>\n",
       "      <td>0.757477</td>\n",
       "      <td>1.693925</td>\n",
       "      <td>1.771569</td>\n",
       "      <td>-0.181694</td>\n",
       "      <td>-0.284896</td>\n",
       "      <td>-0.348145</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.511269</td>\n",
       "      <td>-0.701698</td>\n",
       "      <td>-0.741230</td>\n",
       "      <td>-0.638897</td>\n",
       "      <td>-0.555202</td>\n",
       "      <td>-0.423907</td>\n",
       "      <td>-0.181694</td>\n",
       "      <td>-0.612478</td>\n",
       "      <td>-0.348145</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.552274</td>\n",
       "      <td>1.582044</td>\n",
       "      <td>1.601018</td>\n",
       "      <td>-0.638897</td>\n",
       "      <td>-0.105376</td>\n",
       "      <td>0.124962</td>\n",
       "      <td>-0.181694</td>\n",
       "      <td>1.353016</td>\n",
       "      <td>-0.348145</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.156754</td>\n",
       "      <td>-0.701698</td>\n",
       "      <td>-0.741230</td>\n",
       "      <td>0.059290</td>\n",
       "      <td>-0.555202</td>\n",
       "      <td>-0.698341</td>\n",
       "      <td>-0.181694</td>\n",
       "      <td>-0.612478</td>\n",
       "      <td>-0.348145</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>694</td>\n",
       "      <td>-0.511269</td>\n",
       "      <td>-0.701698</td>\n",
       "      <td>-0.741230</td>\n",
       "      <td>-0.638897</td>\n",
       "      <td>-0.105376</td>\n",
       "      <td>-0.423907</td>\n",
       "      <td>-0.998122</td>\n",
       "      <td>-0.612478</td>\n",
       "      <td>-0.348145</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>695</td>\n",
       "      <td>-0.865783</td>\n",
       "      <td>-0.701698</td>\n",
       "      <td>-0.741230</td>\n",
       "      <td>-0.638897</td>\n",
       "      <td>-0.555202</td>\n",
       "      <td>-0.698341</td>\n",
       "      <td>-0.998122</td>\n",
       "      <td>-0.612478</td>\n",
       "      <td>-0.348145</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>696</td>\n",
       "      <td>0.197760</td>\n",
       "      <td>2.234542</td>\n",
       "      <td>2.270232</td>\n",
       "      <td>0.059290</td>\n",
       "      <td>1.693925</td>\n",
       "      <td>-0.149472</td>\n",
       "      <td>1.859375</td>\n",
       "      <td>2.335764</td>\n",
       "      <td>0.228998</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>697</td>\n",
       "      <td>-0.156754</td>\n",
       "      <td>1.582044</td>\n",
       "      <td>0.931805</td>\n",
       "      <td>0.408383</td>\n",
       "      <td>-0.105376</td>\n",
       "      <td>0.124962</td>\n",
       "      <td>2.675803</td>\n",
       "      <td>1.025434</td>\n",
       "      <td>-0.348145</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>698</td>\n",
       "      <td>-0.156754</td>\n",
       "      <td>1.582044</td>\n",
       "      <td>1.601018</td>\n",
       "      <td>0.757477</td>\n",
       "      <td>0.344449</td>\n",
       "      <td>0.399397</td>\n",
       "      <td>2.675803</td>\n",
       "      <td>0.370269</td>\n",
       "      <td>-0.348145</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>632 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  clump_thickness  unif_cell_size  unif_cell_shape  marg_adhesion  \\\n",
       "0        0         0.197760       -0.701698        -0.741230      -0.638897   \n",
       "1        1         0.197760        0.277049         0.262591       0.757477   \n",
       "2        2        -0.511269       -0.701698        -0.741230      -0.638897   \n",
       "3        3         0.552274        1.582044         1.601018      -0.638897   \n",
       "4        4        -0.156754       -0.701698        -0.741230       0.059290   \n",
       "..     ...              ...             ...              ...            ...   \n",
       "627    694        -0.511269       -0.701698        -0.741230      -0.638897   \n",
       "628    695        -0.865783       -0.701698        -0.741230      -0.638897   \n",
       "629    696         0.197760        2.234542         2.270232       0.059290   \n",
       "630    697        -0.156754        1.582044         0.931805       0.408383   \n",
       "631    698        -0.156754        1.582044         1.601018       0.757477   \n",
       "\n",
       "     single_epith_cell  bare_nuclei  bland_chrom  norm_nucleoli   mitoses  \\\n",
       "0            -0.555202    -0.698341    -0.181694      -0.612478 -0.348145   \n",
       "1             1.693925     1.771569    -0.181694      -0.284896 -0.348145   \n",
       "2            -0.555202    -0.423907    -0.181694      -0.612478 -0.348145   \n",
       "3            -0.105376     0.124962    -0.181694       1.353016 -0.348145   \n",
       "4            -0.555202    -0.698341    -0.181694      -0.612478 -0.348145   \n",
       "..                 ...          ...          ...            ...       ...   \n",
       "627          -0.105376    -0.423907    -0.998122      -0.612478 -0.348145   \n",
       "628          -0.555202    -0.698341    -0.998122      -0.612478 -0.348145   \n",
       "629           1.693925    -0.149472     1.859375       2.335764  0.228998   \n",
       "630          -0.105376     0.124962     2.675803       1.025434 -0.348145   \n",
       "631           0.344449     0.399397     2.675803       0.370269 -0.348145   \n",
       "\n",
       "     class  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "..     ...  \n",
       "627    0.0  \n",
       "628    0.0  \n",
       "629    1.0  \n",
       "630    1.0  \n",
       "631    1.0  \n",
       "\n",
       "[632 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index()\n",
    "df['class'] = df['class'].replace({2:0,4:1})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f23b00be-6721-43d9-af33-f8a831715fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = df.to_numpy()\n",
    "np.random.shuffle(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7a792a-1457-408b-b8fc-2e0c114671db",
   "metadata": {},
   "source": [
    "### KNN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e227defb-874a-4c96-9b8c-3cfd3ff2a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(X_train, X_test, y_train, k=1):\n",
    "    distances = np.linalg.norm(X_train[:, np.newaxis] - X_test, axis=2)\n",
    "    #print(distances.shape, \"\\n\", distances, end=\"\\n\\n\\n\\n\")\n",
    "    \n",
    "    nn_class = y_train[np.argsort(distances, axis=0)[:k]].astype(int)\n",
    "    #print(nn_class.shape, \"\\n\", nn_class, end=\"\\n\\n\\n\\n\")\n",
    "    \n",
    "    predictions = mode(nn_class, axis=0).mode.flatten()\n",
    "    \n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b022a527-c5de-49cb-8155-6237503c9ac9",
   "metadata": {},
   "source": [
    "### Determining Optimal $k$ using K-Fold Cross-Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c9859b1-11d3-4821-93a5-772530eac8ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Accuracy: 88.18181818181816 for k = 1\n"
     ]
    }
   ],
   "source": [
    "folds = 10\n",
    "max_acc = 0\n",
    "max_k = 1\n",
    "test = dat[550:,:]           # Testing dataset\n",
    "dat = dat[:550,:]            # Training/Cross-Validation dataset\n",
    "fold_size = dat.shape[0]//folds\n",
    "for k in range(1,100,1):\n",
    "    acc = 0\n",
    "    for i in range(folds):\n",
    "        X_test = dat[fold_size*i:fold_size*(i+1),:-1]\n",
    "        y_test = dat[fold_size*i:fold_size*(i+1),-1]\n",
    "\n",
    "        X_train = np.vstack((dat[:fold_size*i,:-1],dat[fold_size*(i+1):,:-1]))\n",
    "        y_train = np.hstack((dat[:fold_size*i,-1],dat[fold_size*(i+1):,-1]))\n",
    "\n",
    "        #print(X_test.shape, X_train.shape)\n",
    "        #print(y_test.shape, y_train.shape)\n",
    "    \n",
    "        predictions = KNN(X_train, X_test, y_train, k=k)\n",
    "        acc += (np.sum(predictions == y_test) / fold_size) * 100\n",
    "    acc /= folds\n",
    "    #print(acc)\n",
    "    if acc > max_acc:\n",
    "        max_acc = acc\n",
    "        max_k = k\n",
    "\n",
    "print(\"Maximum Accuracy:\", max_acc, \"for k =\", max_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b2f2ae-638b-42c6-a3bf-f795216c48a3",
   "metadata": {},
   "source": [
    "### Final Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "474b7c43-8bb0-4d6c-ba65-281580921e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 87.8048780487805\n"
     ]
    }
   ],
   "source": [
    "predictions = KNN(dat[:550,:-1], test[:,:-1], dat[:550,-1], k=max_k)\n",
    "acc = (np.sum(predictions == test[:,-1]))/ test.shape[0] * 100\n",
    "print(\"Final Accuracy:\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
